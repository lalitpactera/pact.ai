{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtts import gTTS  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytext = \"Welcome to the demonstration of our Pact AI platform, for building and deploying machine learning models, on various kind of structured or unstructured data,. Pact AI is a web based easy to use application, it can be deployed on any cloud platform,. Pact AI can be used in two modes Automatic mode or Custom mode, based on the business requirements,.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "language = 'en'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "myobj = gTTS(text=mytext, lang=language, slow=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "myobj.save(\"1.mp3\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytext = \"As part of this demonstration, we will showcase how Pact.Ai can be used to build AI models, with ease using either of the two modes. In addition, we shall also showcase a few pretrained usecases, covering different types of data and business needs. We shall start with demonstraion with a pretrained usecase, chest X-ray image classification. \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "language = 'en'\n",
    "myobj = gTTS(text=mytext, lang=language, slow=False) \n",
    "myobj.save(\"2.mp3\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytext = \"Chest radiography, is typically used as an initial diagnostic assessment tool by radiologists, for over 50 thoracic abnormalities such as tuberculosis, pneumonia, nodules, mass and cardiomegaly,. Interpretation of these radiographs is a tedious job, which is further multiplied, by the ratio of number of CXR to that of well-trained radiologists. A deep learning tool, that can discard atleast normal radiographs, can save time and cost for the, hospitals and insurance companies,. We have build this tool using 35000 check X-ray images, trained using deep learning model ResNet50.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "language = 'en'\n",
    "myobj = gTTS(text=mytext, lang=language, slow=False) \n",
    "myobj.save(\"3.mp3\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytext = \"To verify or diagnose, that the chest X-ray image is normal or abnormal, we need to upload the image, using choose button, and then,\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "language = 'en'\n",
    "myobj = gTTS(text=mytext, lang=language, slow=False) \n",
    "myobj.save(\"4.mp3\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytext = \"click upload and submit. Within few miliseconds,\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "language = 'en'\n",
    "myobj = gTTS(text=mytext, lang=language, slow=False) \n",
    "myobj.save(\"5.mp3\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytext = \"we shall obtain the results, that this patient is normal or abnormal,. The algorithm showed 87% accuracy, in identifying abnormal radiographs. This can be further improved, to take this system to clinically acceptable accuracy.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "language = 'en'\n",
    "myobj = gTTS(text=mytext, lang=language, slow=False) \n",
    "myobj.save(\"6.mp3\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytext = \"Now we shall demonstrate another usecase, which is highly relevant for heavy industries,. Based on the task at hand, professonals working in heavy industry, can get information on the risk involved, for this task using our model,. In addition system also guides the professionals, with neccessary precautions based on, previous injuries reported for the similar task,.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "language = 'en'\n",
    "myobj = gTTS(text=mytext, lang=language, slow=False) \n",
    "myobj.save(\"7.mp3\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytext = \"The usuage remains very similar, we shall enter the task description, or load a file with tasks listed, and select the option upload and submit,. Within few seconds, \"\n",
    "language = 'en'\n",
    "myobj = gTTS(text=mytext, lang=language, slow=False) \n",
    "myobj.save(\"8.mp3\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytext = \"we shall see the results on screen, which shows the risk involved in a graphical plot,. Also it shows the previous injuries reported due to this task,. The application is build using Pact AI platform, it involves text classification, and text similarity matching,.\"\n",
    "language = 'en'\n",
    "myobj = gTTS(text=mytext, lang=language, slow=False) \n",
    "myobj.save(\"9.mp3\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytext = \"Now we shall discuss, how Pact AI can help to build models, using custom machine learning mode,. Using the option data pipeline and modeling from home screen,\"\n",
    "language = 'en'\n",
    "myobj = gTTS(text=mytext, lang=language, slow=False) \n",
    "myobj.save(\"10.mp3\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytext = \"We shall see a sandbox or AI work bench, here we have various operations on the left pannel, and work area on the right, where these operations can be dragged and dropped. By selecting seqeunce of options, based on the required business objective, we shall create a data pipeline, or a machine learning model. For instance, for the dataset as shown, if we want to clean this dataset, by removing duplicate entries, and removing missing entries.\"\n",
    "language = 'en'\n",
    "myobj = gTTS(text=mytext, lang=language, slow=False) \n",
    "myobj.save(\"11.mp3\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytext = \"All we need to do is drag relevant options, and connect them. Then select run option to execute the pipeline, download the results, to observe that data, is now clean as we desired,. Similarly, if we want to build the logistic regression based model, for the same dataset.\"\n",
    "language = 'en'\n",
    "myobj = gTTS(text=mytext, lang=language, slow=False) \n",
    "myobj.save(\"12.mp3\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytext = \"We will need the pipe line as shown. For logistic regression, we can further specify parameters, and also select percentage of data, to be used for testing,. After finalizing all options,\"\n",
    "language = 'en'\n",
    "myobj = gTTS(text=mytext, lang=language, slow=False) \n",
    "myobj.save(\"13.mp3\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytext = \"we exceute the pipeline, now our model is ready. We can also see the results, on the previously selected test data, using download results option.\"\n",
    "language = 'en'\n",
    "myobj = gTTS(text=mytext, lang=language, slow=False) \n",
    "myobj.save(\"14.mp3\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytext = \"We can also use the same system, for various operations on text data,. We also have options to upload, and use unstructured text dataset.\"\n",
    "language = 'en'\n",
    "myobj = gTTS(text=mytext, lang=language, slow=False) \n",
    "myobj.save(\"15.mp3\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytext = \"Now we move to second objective of this demonstration, i.e. training our own model,. Let us consider the same dataset, this is now divided into train and test set,.\"\n",
    "language = 'en'\n",
    "myobj = gTTS(text=mytext, lang=language, slow=False) \n",
    "myobj.save(\"16.mp3\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytext = \"In user interface we select our objective, which is data classification in this case, we also select the train data, enter features and the target columns, and click on upload and submit,. Within few seconds our model is trained,. Here we have not defined any steps such as remove duplicates, or remove or impute missing data, or even logistic regression parameters,. The best model with the most optimal hyper parameters are automatecally selected by the system,.\"\n",
    "language = 'en'\n",
    "myobj = gTTS(text=mytext, lang=language, slow=False) \n",
    "myobj.save(\"17.mp3\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytext = \"This new model is now deployed and can be used, using test model option from the home page.\"\n",
    "language = 'en'\n",
    "myobj = gTTS(text=mytext, lang=language, slow=False) \n",
    "myobj.save(\"18.mp3\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytext = \"To test your model, select, load or enter the test data, features and the target are already defined,. And click on upload and submit,.\"\n",
    "language = 'en'\n",
    "myobj = gTTS(text=mytext, lang=language, slow=False) \n",
    "myobj.save(\"19.mp3\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytext = \"Results can now be downloaded,. As you can observe most of the results match accurately with the ground truth,. There is one error, this might be due to ambiguity in the dataset,. Which can be handled by data preprocessing steps such as outlier detection,.\"\n",
    "language = 'en'\n",
    "myobj = gTTS(text=mytext, lang=language, slow=False) \n",
    "myobj.save(\"20.mp3\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytext = \"With this we have completed demostration of this platform,. please send us your suggestions/ comments,. Thank you for your attention,.\"\n",
    "language = 'en'\n",
    "myobj = gTTS(text=mytext, lang=language, slow=False) \n",
    "myobj.save(\"21.mp3\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "No text to speak",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-750cd482dc26>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmytext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mlanguage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'en'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmyobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgTTS\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmytext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mmyobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"20.mp3\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\p0140563\\miniconda3\\lib\\site-packages\\gtts\\tts.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, text, lang, slow, lang_check, pre_processor_funcs, tokenizer_func)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[1;31m# Text\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m         \u001b[1;32massert\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'No text to speak'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: No text to speak"
     ]
    }
   ],
   "source": [
    "mytext = \"\"\n",
    "language = 'en'\n",
    "myobj = gTTS(text=mytext, lang=language, slow=False) \n",
    "myobj.save(\"20.mp3\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyttsx3 \n",
    "  \n",
    "# initialisation \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = pyttsx3.init() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "# testing \n",
    "engine.say(\"My first code on text-to-speech\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.runAndWait() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.save_to_file('the text I want to save as audio', 'test.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
